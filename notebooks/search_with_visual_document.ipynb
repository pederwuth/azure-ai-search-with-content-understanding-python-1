{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visual Document Search with Azure Content Understanding\n",
    "## Objective\n",
    "This document illustrates an example workflow for how to leverage the Azure AI Content Understanding API to enhance the quality of document search.\n",
    "\n",
    "The sample will demonstrate the following steps:\n",
    "1. Extract the layout and content of a document using Azure AI Document Intelligence.\n",
    "2. For each figure in the document, extract its content with a custom analyzer using Azure AI Content Understanding, and insert it into the corresponding location in the document content.\n",
    "2. Chunk and embed the document content with LangChain and Azure OpenAI, and index them with Azure Search to generate an Azure Search index.\n",
    "3. Utilize an OpenAI chat model to search through content in the document with a natural language query.\n",
    "\n",
    "\n",
    "## Pre-requisites\n",
    "1. Follow the [README](../README.md#configure-azure-ai-service-resource) to create the required resources for this sample.\n",
    "1. Install the required packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv(override=True)\n",
    "\n",
    "# Load and validate Azure AI Services configs\n",
    "AZURE_AI_SERVICE_ENDPOINT = os.getenv(\"AZURE_AI_SERVICE_ENDPOINT\")\n",
    "AZURE_AI_SERVICE_API_VERSION = os.getenv(\"AZURE_AI_SERVICE_API_VERSION\") or \"2024-12-01-preview\"\n",
    "AZURE_DOCUMENT_INTELLIGENCE_API_VERSION = os.getenv(\"AZURE_DOCUMENT_INTELLIGENCE_API_VERSION\") or \"2024-11-30\"\n",
    "\n",
    "# Load and validate Azure OpenAI configs\n",
    "AZURE_OPENAI_ENDPOINT = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "AZURE_OPENAI_CHAT_DEPLOYMENT_NAME = os.getenv(\"AZURE_OPENAI_CHAT_DEPLOYMENT_NAME\")\n",
    "AZURE_OPENAI_CHAT_API_VERSION = os.getenv(\"AZURE_OPENAI_CHAT_API_VERSION\") or \"2024-08-01-preview\"\n",
    "AZURE_OPENAI_EMBEDDING_DEPLOYMENT_NAME = os.getenv(\"AZURE_OPENAI_EMBEDDING_DEPLOYMENT_NAME\")\n",
    "AZURE_OPENAI_EMBEDDING_API_VERSION = os.getenv(\"AZURE_OPENAI_EMBEDDING_API_VERSION\") or \"2023-05-15\"\n",
    "\n",
    "# Load and validate Azure Search Services configs\n",
    "AZURE_SEARCH_ENDPOINT = os.getenv(\"AZURE_SEARCH_ENDPOINT\")\n",
    "AZURE_SEARCH_INDEX_NAME = os.getenv(\"AZURE_SEARCH_INDEX_NAME\") or \"sample-index-visual-doc\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File to analyze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# Get the path to the file that will be analyzed\n",
    "# Testing with Venture Deals - a full book\n",
    "file = Path(\"../data/Venture-deals.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create custom analyzer using chart and diagram understanding template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzer details for content-understanding-search-sample-2511c091-f01c-422d-a78a-f260d03c6f46:\n",
      "{\n",
      "  \"id\": \"a93385eb-d3fb-4594-8547-d5868d185f60\",\n",
      "  \"status\": \"Succeeded\",\n",
      "  \"result\": {\n",
      "    \"analyzerId\": \"content-understanding-search-sample-2511c091-f01c-422d-a78a-f260d03c6f46\",\n",
      "    \"description\": \"Extract detailed structured information from charts and diagrams.\",\n",
      "    \"createdAt\": \"2025-10-04T12:06:27Z\",\n",
      "    \"lastModifiedAt\": \"2025-10-04T12:06:27Z\",\n",
      "    \"config\": {\n",
      "      \"returnDetails\": false,\n",
      "      \"disableContentFiltering\": false\n",
      "    },\n",
      "    \"fieldSchema\": {\n",
      "      \"name\": \"ChartsAndDiagrams\",\n",
      "      \"fields\": {\n",
      "        \"Title\": {\n",
      "          \"type\": \"string\",\n",
      "          \"description\": \"Verbatim title of the chart.\"\n",
      "        },\n",
      "        \"ChartType\": {\n",
      "          \"type\": \"string\",\n",
      "          \"description\": \"The type of chart.\",\n",
      "          \"enum\": [\n",
      "            \"area\",\n",
      "            \"bar\",\n",
      "            \"box\",\n",
      "            \"bubble\",\n",
      "            \"candlestick\",\n",
      "            \"funnel\",\n",
      "            \"heatmap\",\n",
      "            \"histogram\",\n",
      "            \"line\",\n",
      "            \"pie\",\n",
      "            \"radar\",\n",
      "            \"rings\",\n",
      "            \"rose\",\n",
      "            \"treemap\"\n",
      "          ],\n",
      "          \"enumDescriptions\": {\n",
      "            \"histogram\": \"Continuous values on the x-axis, which distinguishes it from bar.\",\n",
      "            \"rose\": \"In contrast to pie charts, the sectors are of equal angles and differ in how far each sector extends from the center of the circle.\"\n",
      "          }\n",
      "        },\n",
      "        \"TopicKeywords\": {\n",
      "          \"type\": \"array\",\n",
      "          \"description\": \"Relevant topics associated with the chart, used for tagging.\",\n",
      "          \"items\": {\n",
      "            \"type\": \"string\",\n",
      "            \"examples\": [\n",
      "              \"Business and finance\",\n",
      "              \"Arts and culture\",\n",
      "              \"Education and academics\"\n",
      "            ]\n",
      "          }\n",
      "        },\n",
      "        \"DetailedDescription\": {\n",
      "          \"type\": \"string\",\n",
      "          \"description\": \"Detailed description of the chart or diagram, not leaving out any key information. Include numbers, trends, and other details.\"\n",
      "        },\n",
      "        \"Summary\": {\n",
      "          \"type\": \"string\",\n",
      "          \"description\": \"Detailed summary of the chart, including highlights and takeaways.\"\n",
      "        },\n",
      "        \"MarkdownDataTable\": {\n",
      "          \"type\": \"string\",\n",
      "          \"description\": \"Underlying data of the chart in tabular markdown format. Give markdown output with valid syntax and accurate numbers, and fill any uncertain values with empty cells. If not applicable, output an empty string.\"\n",
      "        },\n",
      "        \"AxisTitles\": {\n",
      "          \"type\": \"object\",\n",
      "          \"description\": \"Titles of the x and y axes.\",\n",
      "          \"properties\": {\n",
      "            \"xAxisTitle\": {\n",
      "              \"type\": \"string\"\n",
      "            },\n",
      "            \"yAxisTitle\": {\n",
      "              \"type\": \"string\"\n",
      "            }\n",
      "          }\n",
      "        },\n",
      "        \"FootnotesAndAnnotations\": {\n",
      "          \"type\": \"string\",\n",
      "          \"description\": \"All footnotes and textual annotations in the chart or diagram.\"\n",
      "        }\n",
      "      }\n",
      "    },\n",
      "    \"warnings\": [],\n",
      "    \"status\": \"ready\",\n",
      "    \"scenario\": \"image\"\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import sys\n",
    "import uuid\n",
    "\n",
    "# Add the parent directory to the path to use shared modules\n",
    "parent_dir = Path(Path.cwd()).parent\n",
    "sys.path.append(str(parent_dir))\n",
    "from python.content_understanding_client import AzureContentUnderstandingClient\n",
    "\n",
    "from azure.identity import DefaultAzureCredential, get_bearer_token_provider\n",
    "credential = DefaultAzureCredential()\n",
    "token_provider = get_bearer_token_provider(credential, \"https://cognitiveservices.azure.com/.default\")\n",
    "\n",
    "# Get path to sample template\n",
    "ANALYZER_TEMPLATE_PATH = \"../analyzer_templates/image_chart_diagram_understanding.json\"\n",
    "\n",
    "# Create analyzer\n",
    "ANALYZER_ID = \"content-understanding-search-sample-\" + str(uuid.uuid4())\n",
    "content_understanding_client = AzureContentUnderstandingClient(\n",
    "    endpoint=AZURE_AI_SERVICE_ENDPOINT,\n",
    "    api_version=AZURE_AI_SERVICE_API_VERSION,\n",
    "    token_provider=token_provider,\n",
    "    x_ms_useragent=\"azure-ai-content-understanding-python/search_with_visusal_document\", # This header is used for sample usage telemetry, please comment out this line if you want to opt out.\n",
    ")\n",
    "\n",
    "try:\n",
    "    response = content_understanding_client.begin_create_analyzer(ANALYZER_ID, analyzer_template_path=ANALYZER_TEMPLATE_PATH)\n",
    "    result = content_understanding_client.poll_result(response)\n",
    "    print(f'Analyzer details for {result[\"result\"][\"analyzerId\"]}:')\n",
    "    print(json.dumps(result, indent=2))\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    print(\"Error in creating analyzer. Please double-check your analysis settings.\\nIf there is a conflict, you can delete the analyzer and then recreate it, or move to the next cell and use the existing analyzer.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze document layout and compose with figure descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.documentintelligence import DocumentIntelligenceClient\n",
    "from azure.ai.documentintelligence.models import AnalyzeResult\n",
    "from azure.ai.documentintelligence.models import AnalyzeDocumentRequest\n",
    "import fitz\n",
    "from PIL import Image\n",
    "\n",
    "# Define helper functions for document-figure composition\n",
    "def insert_figure_contents(md_content, figure_contents, span_offsets):\n",
    "    \"\"\"\n",
    "    Inserts the figure content for each of the provided figures in figure_contents\n",
    "    before the span offset of that figure in the given markdown content.\n",
    "\n",
    "    Args:\n",
    "    - md_content (str): The original markdown content.\n",
    "    - figure_contents (list[str]): The contents of each figure to insert.\n",
    "    - span_offsets (list[int]): The span offsets of each figure in order. These should be sorted and strictly increasing.\n",
    "\n",
    "    Returns:\n",
    "    - str: The modified markdown content with the the figure contents prepended to each figure's span.\n",
    "    \"\"\"\n",
    "    # NOTE: In this notebook, we only alter the Markdown content returned by the Document Intelligence API,\n",
    "    # and not the per-element spans in the API response. Thus, after figure content insertion, these per-element spans will be inaccurate.\n",
    "    # This may impact use cases like citation page number calculation.\n",
    "    # Additional code may be needed to correct the spans or otherwise infer the page numbers for each citation.\n",
    "    # The main purpose of the notebook is to show the feasibility of using Content Understanding with Azure Search for RAG chat applications.\n",
    "\n",
    "    # Validate span_offsets are sorted and strictly increasing\n",
    "    if span_offsets != sorted(span_offsets) or not all([o < span_offsets[i + 1] for i, o in enumerate(span_offsets) if i < len(span_offsets) - 1]):\n",
    "        raise ValueError(\"span_offsets should be sorted and strictly increasing.\")\n",
    "\n",
    "    # Split the content based on the provided spans\n",
    "    parts = []\n",
    "    preamble = None\n",
    "    for i, offset in enumerate(span_offsets):\n",
    "        if i == 0 and offset > 0:\n",
    "            preamble = md_content[0:offset]\n",
    "            parts.append(md_content[offset:span_offsets[i + 1]])\n",
    "        elif i == len(span_offsets) - 1:\n",
    "            parts.append(md_content[offset:])\n",
    "        else:\n",
    "            parts.append(md_content[offset:span_offsets[i + 1]])\n",
    "\n",
    "    # Join the parts back together with the figure content inserted\n",
    "    modified_content = \"\"\n",
    "    if preamble:\n",
    "        modified_content += preamble\n",
    "    for i, part in enumerate(parts):\n",
    "        modified_content += f\"<!-- FigureContent=\\\"{figure_contents[i]}\\\" -->\" + part\n",
    "\n",
    "    return modified_content\n",
    "\n",
    "def crop_image_from_pdf_page(pdf_path, page_number, bounding_box):\n",
    "    \"\"\"\n",
    "    Crops a region from a given page in a PDF and returns it as an image.\n",
    "\n",
    "    Args:    \n",
    "    - pdf_path (pathlib.Path): Path to the PDF file.\n",
    "    - page_number (int): The page number to crop from (0-indexed).\n",
    "    - bounding_box (tuple): A tuple of (x0, y0, x1, y1) coordinates for the bounding box.\n",
    "    \n",
    "    Returns:\n",
    "    - PIL.Image: A PIL Image of the cropped area.\n",
    "    \"\"\"\n",
    "    doc = fitz.open(pdf_path)\n",
    "    page = doc.load_page(page_number)\n",
    "    \n",
    "    # Cropping the page. The rect requires the coordinates in the format (x0, y0, x1, y1).\n",
    "    bbx = [x * 72 for x in bounding_box]\n",
    "    rect = fitz.Rect(bbx)\n",
    "    pix = page.get_pixmap(matrix=fitz.Matrix(300 / 72, 300 / 72), clip=rect)\n",
    "    \n",
    "    img = Image.frombytes(\"RGB\", [pix.width, pix.height], pix.samples)\n",
    "    \n",
    "    doc.close()\n",
    "\n",
    "    return img\n",
    "\n",
    "def format_content_understanding_result(content_understanding_result):\n",
    "    \"\"\"\n",
    "    Formats the JSON output of the Content Understanding result as Markdown for downstream usage in text.\n",
    "    \n",
    "    Args:\n",
    "    - content_understanding_result (dict): A dictionary containing the output from Content Understanding.\n",
    "\n",
    "    Returns:\n",
    "    - str: A Markdown string of the result content.\n",
    "    \"\"\"\n",
    "    def _format_result(key, result):\n",
    "        result_type = result[\"type\"]\n",
    "        if result_type in [\"string\", \"integer\", \"number\", \"boolean\"]:\n",
    "            return f\"**{key}**: \" + str(result[f'value{result_type.capitalize()}']) + \"\\n\"\n",
    "        elif result_type == \"array\":\n",
    "            return f\"**{key}**: \" + ', '.join([str(result[\"valueArray\"][i][f\"value{r['type'].capitalize()}\"]) for i, r in enumerate(result[\"valueArray\"])]) + \"\\n\"\n",
    "        elif result_type == \"object\":\n",
    "            return f\"**{key}**\\n\" + ''.join([_format_result(f\"{key}.{k}\", result[\"valueObject\"][k]) for k in result[\"valueObject\"]])\n",
    "\n",
    "    fields = content_understanding_result['result']['contents'][0]['fields']\n",
    "    markdown_result = \"\"\n",
    "    for field in fields:\n",
    "        markdown_result += _format_result(field, fields[field])\n",
    "\n",
    "    return markdown_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Created job folder: ../content/books/Venture-deals_textbook_20251004-120709\n",
      "✓ Copied input PDF to: ../content/books/Venture-deals_textbook_20251004-120709/input/Venture-deals.pdf\n",
      "\n",
      "======================================================================\n",
      "STEP 1: Extract chapters with Content Understanding\n",
      "======================================================================\n",
      "Started: 12:07:09\n",
      "  → Sending document for chapter analysis...\n",
      "  → Waiting for chapter extraction to complete (this may take a few minutes)...\n",
      "  → Waiting for chapter extraction to complete (this may take a few minutes)...\n",
      "  → Chapter extraction completed at 12:10:55\n",
      "\n",
      "✓ Extracted 1 chapters\n",
      "✓ Document: Venture Deals: Be Smarter than Your Lawyer and Venture Capitalist, Third Edition...\n",
      "  1. 12.: How to Raise Money (Pages 0-0, Level 1)\n",
      "\n",
      "======================================================================\n",
      "STEP 2: Extract layout and figures with Document Intelligence\n",
      "======================================================================\n",
      "Started: 12:10:55\n",
      "  → Document size: 1.58 MB\n",
      "  → Analyzing document layout...\n",
      "  → Chapter extraction completed at 12:10:55\n",
      "\n",
      "✓ Extracted 1 chapters\n",
      "✓ Document: Venture Deals: Be Smarter than Your Lawyer and Venture Capitalist, Third Edition...\n",
      "  1. 12.: How to Raise Money (Pages 0-0, Level 1)\n",
      "\n",
      "======================================================================\n",
      "STEP 2: Extract layout and figures with Document Intelligence\n",
      "======================================================================\n",
      "Started: 12:10:55\n",
      "  → Document size: 1.58 MB\n",
      "  → Analyzing document layout...\n",
      "✓ Extracted document content (628136 characters)\n",
      "✓ Detected 16 figures\n",
      "  Completed at: 12:11:21\n",
      "\n",
      "======================================================================\n",
      "STEP 3: Analyze figures with Content Understanding\n",
      "======================================================================\n",
      "Started: 12:11:21\n",
      "Extracting figure contents with Content Understanding image analyzer...\n",
      "Total figures to process: 16\n",
      "✓ Extracted document content (628136 characters)\n",
      "✓ Detected 16 figures\n",
      "  Completed at: 12:11:21\n",
      "\n",
      "======================================================================\n",
      "STEP 3: Analyze figures with Content Understanding\n",
      "======================================================================\n",
      "Started: 12:11:21\n",
      "Extracting figure contents with Content Understanding image analyzer...\n",
      "Total figures to process: 16\n",
      "  ✓ Figure 1/16 analyzed (page 1) - 6.2% complete\n",
      "  ✓ Figure 1/16 analyzed (page 1) - 6.2% complete\n",
      "  ✓ Figure 2/16 analyzed (page 38) - 12.5% complete\n",
      "  ✓ Figure 2/16 analyzed (page 38) - 12.5% complete\n",
      "  ✓ Figure 3/16 analyzed (page 56) - 18.8% complete\n",
      "  ✓ Figure 3/16 analyzed (page 56) - 18.8% complete\n",
      "  ✓ Figure 4/16 analyzed (page 58) - 25.0% complete\n",
      "  ✓ Figure 4/16 analyzed (page 58) - 25.0% complete\n",
      "  ✓ Figure 5/16 analyzed (page 86) - 31.2% complete\n",
      "  ✓ Figure 5/16 analyzed (page 86) - 31.2% complete\n",
      "  ✓ Figure 6/16 analyzed (page 99) - 37.5% complete\n",
      "  ✓ Figure 6/16 analyzed (page 99) - 37.5% complete\n",
      "  ✓ Figure 7/16 analyzed (page 123) - 43.8% complete\n",
      "  ✓ Figure 7/16 analyzed (page 123) - 43.8% complete\n",
      "  ✓ Figure 8/16 analyzed (page 139) - 50.0% complete\n",
      "  ✓ Figure 8/16 analyzed (page 139) - 50.0% complete\n",
      "  ✓ Figure 9/16 analyzed (page 145) - 56.2% complete\n",
      "  ✓ Figure 9/16 analyzed (page 145) - 56.2% complete\n",
      "  ✓ Figure 10/16 analyzed (page 146) - 62.5% complete\n",
      "  ✓ Figure 10/16 analyzed (page 146) - 62.5% complete\n",
      "  ✓ Figure 11/16 analyzed (page 163) - 68.8% complete\n",
      "  ✓ Figure 11/16 analyzed (page 163) - 68.8% complete\n",
      "  ✓ Figure 12/16 analyzed (page 181) - 75.0% complete\n",
      "  ✓ Figure 12/16 analyzed (page 181) - 75.0% complete\n",
      "  ✓ Figure 13/16 analyzed (page 186) - 81.2% complete\n",
      "  ✓ Figure 13/16 analyzed (page 186) - 81.2% complete\n",
      "  ✓ Figure 14/16 analyzed (page 190) - 87.5% complete\n",
      "  ✓ Figure 14/16 analyzed (page 190) - 87.5% complete\n",
      "  ✓ Figure 15/16 analyzed (page 212) - 93.8% complete\n",
      "  ✓ Figure 15/16 analyzed (page 212) - 93.8% complete\n",
      "  ✓ Figure 16/16 analyzed (page 217) - 100.0% complete\n",
      "\n",
      "✓ Analyzed 16 figures\n",
      "  Completed at: 12:13:12\n",
      "  → Inserting figure descriptions into document...\n",
      "\n",
      "======================================================================\n",
      "STEP 4: Save enhanced document with chapter metadata\n",
      "======================================================================\n",
      "  ✓ Figure 16/16 analyzed (page 217) - 100.0% complete\n",
      "\n",
      "✓ Analyzed 16 figures\n",
      "  Completed at: 12:13:12\n",
      "  → Inserting figure descriptions into document...\n",
      "\n",
      "======================================================================\n",
      "STEP 4: Save enhanced document with chapter metadata\n",
      "======================================================================\n",
      "\n",
      "✓ All files saved to: ../content/books/Venture-deals_textbook_20251004-120709\n",
      "\n",
      "  Input:\n",
      "    - Venture-deals.pdf\n",
      "\n",
      "  Processed:\n",
      "    - Venture-deals_textbook_cache_20251004-120709.json (45.72 MB)\n",
      "    - Venture-deals_textbook_markdown_20251004-120709.md (624.8 KB)\n",
      "    - Venture-deals_textbook_metadata_20251004-120709.json\n",
      "\n",
      "  Summary:\n",
      "    - 1 chapters with metadata\n",
      "    - 16 figures analyzed\n",
      "    - 639,749 characters in markdown\n",
      "\n",
      "Total process completed at: 12:13:15\n",
      "\n",
      "✓ All files saved to: ../content/books/Venture-deals_textbook_20251004-120709\n",
      "\n",
      "  Input:\n",
      "    - Venture-deals.pdf\n",
      "\n",
      "  Processed:\n",
      "    - Venture-deals_textbook_cache_20251004-120709.json (45.72 MB)\n",
      "    - Venture-deals_textbook_markdown_20251004-120709.md (624.8 KB)\n",
      "    - Venture-deals_textbook_metadata_20251004-120709.json\n",
      "\n",
      "  Summary:\n",
      "    - 1 chapters with metadata\n",
      "    - 16 figures analyzed\n",
      "    - 639,749 characters in markdown\n",
      "\n",
      "Total process completed at: 12:13:15\n"
     ]
    }
   ],
   "source": [
    "import io\n",
    "import json\n",
    "import os\n",
    "import shutil\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "# Configuration\n",
    "CONTENT_TYPE = \"textbook\"  # Can be changed to other types like \"novel\", \"academic\", etc.\n",
    "\n",
    "# Generate timestamp and setup folder structure\n",
    "timestamp = datetime.now().strftime('%Y%m%d-%H%M%S')\n",
    "bookname = file.stem  # Extract filename without extension (e.g., \"Venture-deals\")\n",
    "job_folder_name = f\"{bookname}_{CONTENT_TYPE}_{timestamp}\"\n",
    "\n",
    "# Create folder structure: content/books/{bookname}_{contenttype}_{timestamp}/\n",
    "books_root = Path(\"../content/books\")\n",
    "job_folder = books_root / job_folder_name\n",
    "input_folder = job_folder / \"input\"\n",
    "processed_folder = job_folder / \"processed\"\n",
    "\n",
    "# Create directories\n",
    "input_folder.mkdir(parents=True, exist_ok=True)\n",
    "processed_folder.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Copy original PDF to input folder\n",
    "original_pdf_dest = input_folder / file.name\n",
    "shutil.copy2(file, original_pdf_dest)\n",
    "print(f\"✓ Created job folder: {job_folder}\")\n",
    "print(f\"✓ Copied input PDF to: {original_pdf_dest}\")\n",
    "\n",
    "# Initialize empty structures for chapter data (will be populated by LLM later)\n",
    "chapters = []\n",
    "document_metadata = {\n",
    "    \"title\": \"\",\n",
    "    \"summary\": \"\"\n",
    "}\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"STEP 1: Extract layout and figures with Document Intelligence\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"Started: {datetime.now().strftime('%H:%M:%S')}\")\n",
    "\n",
    "# Run Content Understanding on each figure, format figure contents, and insert figure contents into corresponding document locations\n",
    "with open(file, 'rb') as f:\n",
    "    pdf_bytes = f.read()\n",
    "    print(f\"  → Document size: {len(pdf_bytes) / 1024 / 1024:.2f} MB\")\n",
    "\n",
    "    document_intelligence_client = DocumentIntelligenceClient(\n",
    "        endpoint=AZURE_AI_SERVICE_ENDPOINT,\n",
    "        api_version=AZURE_DOCUMENT_INTELLIGENCE_API_VERSION,\n",
    "        credential=credential,\n",
    "        output=str('figures')\n",
    "    )\n",
    "\n",
    "    print(\"  → Analyzing document layout...\")\n",
    "    poller = document_intelligence_client.begin_analyze_document(\n",
    "        \"prebuilt-layout\",\n",
    "        AnalyzeDocumentRequest(bytes_source=pdf_bytes),\n",
    "        output=[str('figures')],\n",
    "        features=['ocrHighResolution'],\n",
    "        output_content_format=\"markdown\"\n",
    "    )\n",
    "\n",
    "    result: AnalyzeResult = poller.result()\n",
    "    \n",
    "    md_content = result.content\n",
    "\n",
    "    print(f\"✓ Extracted document content ({len(md_content)} characters)\")\n",
    "    print(f\"✓ Detected {len(result.figures) if result.figures else 0} figures\")\n",
    "    print(f\"  Completed at: {datetime.now().strftime('%H:%M:%S')}\")\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"STEP 3: Analyze figures with Content Understanding\")\n",
    "    print(\"=\" * 70)\n",
    "    print(f\"Started: {datetime.now().strftime('%H:%M:%S')}\")\n",
    "\n",
    "    figure_contents = []\n",
    "    if result.figures:\n",
    "        total_figures = len(result.figures)\n",
    "        print(f\"Extracting figure contents with Content Understanding image analyzer...\")\n",
    "        print(f\"Total figures to process: {total_figures}\")\n",
    "        \n",
    "        for figure_idx, figure in enumerate(result.figures):\n",
    "            for region in figure.bounding_regions:\n",
    "                    # Uncomment the below to print out the bounding regions of each figure\n",
    "                    # print(f\"Figure {figure_idx + 1} body bounding regions: {region}\")\n",
    "                    # To learn more about bounding regions, see https://aka.ms/bounding-region\n",
    "                    bounding_box = (\n",
    "                            region.polygon[0],  # x0 (left)\n",
    "                            region.polygon[1],  # y0 (top\n",
    "                            region.polygon[4],  # x1 (right)\n",
    "                            region.polygon[5]   # y1 (bottom)\n",
    "                        )\n",
    "            page_number = figure.bounding_regions[0]['pageNumber']\n",
    "            cropped_img = crop_image_from_pdf_page(file, page_number - 1, bounding_box)\n",
    "\n",
    "            os.makedirs(\"figures\", exist_ok=True)\n",
    "\n",
    "            figure_filename = f\"figure_{figure_idx + 1}.png\"\n",
    "            # Full path for the file\n",
    "            figure_filepath = os.path.join(\"figures\", figure_filename)\n",
    "\n",
    "            # Save the figure\n",
    "            cropped_img.save(figure_filepath)\n",
    "            bytes_io = io.BytesIO()\n",
    "            cropped_img.save(bytes_io, format='PNG')\n",
    "            cropped_img = bytes_io.getvalue()\n",
    "\n",
    "            # Collect formatted content from the figure\n",
    "            content_understanding_response = content_understanding_client.begin_analyze(ANALYZER_ID, figure_filepath)\n",
    "            content_understanding_result = content_understanding_client.poll_result(content_understanding_response, timeout_seconds=1000)\n",
    "            figure_content = format_content_understanding_result(content_understanding_result)\n",
    "            figure_contents.append(figure_content)\n",
    "            \n",
    "            # Progress indicator - show every 10 figures or every figure for small sets\n",
    "            if total_figures <= 20 or (figure_idx + 1) % 10 == 0 or (figure_idx + 1) == total_figures:\n",
    "                progress_pct = ((figure_idx + 1) / total_figures) * 100\n",
    "                print(f\"  ✓ Figure {figure_idx + 1}/{total_figures} analyzed (page {page_number}) - {progress_pct:.1f}% complete\")\n",
    "\n",
    "        print(f\"\\n✓ Analyzed {len(figure_contents)} figures\")\n",
    "        print(f\"  Completed at: {datetime.now().strftime('%H:%M:%S')}\")\n",
    "\n",
    "        # Insert figure content into corresponding location in document\n",
    "        print(\"  → Inserting figure descriptions into document...\")\n",
    "        md_content = insert_figure_contents(md_content, figure_contents, [f.spans[0][\"offset\"] for f in result.figures])\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"STEP 4: Save enhanced document with chapter metadata\")\n",
    "    print(\"=\" * 70)\n",
    "\n",
    "    # Save enhanced document with both figure descriptions and chapter metadata\n",
    "    result.content = md_content\n",
    "    output = {\n",
    "        \"analyzeResult\": result.as_dict(),\n",
    "        \"chapters\": chapters,\n",
    "        \"document_metadata\": document_metadata,\n",
    "        \"processing_info\": {\n",
    "            \"timestamp\": timestamp,\n",
    "            \"job_folder\": str(job_folder),\n",
    "            \"bookname\": bookname,\n",
    "            \"content_type\": CONTENT_TYPE,\n",
    "            \"original_file\": str(file),\n",
    "            \"total_chapters\": len(chapters),\n",
    "            \"total_figures\": len(figure_contents)\n",
    "        }\n",
    "    }\n",
    "    output_json = json.dumps(output, indent=2)\n",
    "    \n",
    "    # Save cache JSON with proper naming: {bookname}_{contenttype}_cache_{timestamp}.json\n",
    "    cache_filename = f\"{bookname}_{CONTENT_TYPE}_cache_{timestamp}.json\"\n",
    "    cache_path = processed_folder / cache_filename\n",
    "    with open(cache_path, 'w', encoding='utf-8') as f:\n",
    "        f.write(output_json)\n",
    "    \n",
    "    # Save markdown with proper naming: {bookname}_{contenttype}_markdown_{timestamp}.md\n",
    "    markdown_filename = f\"{bookname}_{CONTENT_TYPE}_markdown_{timestamp}.md\"\n",
    "    markdown_path = processed_folder / markdown_filename\n",
    "    with open(markdown_path, 'w', encoding='utf-8') as f:\n",
    "        f.write(f\"# {document_metadata.get('title', bookname)}\\n\\n\")\n",
    "        f.write(f\"**Document**: {file.name}\\n\")\n",
    "        f.write(f\"**Processed**: {timestamp}\\n\")\n",
    "        f.write(f\"**Content Type**: {CONTENT_TYPE}\\n\\n\")\n",
    "        if document_metadata.get('summary'):\n",
    "            f.write(f\"**Summary**: {document_metadata.get('summary')}\\n\\n\")\n",
    "        f.write(f\"**Total Chapters**: {len(chapters)}\\n\")\n",
    "        f.write(f\"**Total Figures**: {len(figure_contents)}\\n\\n\")\n",
    "        f.write(\"---\\n\\n\")\n",
    "        f.write(md_content)\n",
    "    \n",
    "    # Save metadata summary as separate JSON for quick reference\n",
    "    metadata_filename = f\"{bookname}_{CONTENT_TYPE}_metadata_{timestamp}.json\"\n",
    "    metadata_path = processed_folder / metadata_filename\n",
    "    metadata_summary = {\n",
    "        \"document_title\": document_metadata.get('title', ''),\n",
    "        \"document_summary\": document_metadata.get('summary', ''),\n",
    "        \"bookname\": bookname,\n",
    "        \"content_type\": CONTENT_TYPE,\n",
    "        \"timestamp\": timestamp,\n",
    "        \"original_file\": file.name,\n",
    "        \"total_chapters\": len(chapters),\n",
    "        \"total_figures\": len(figure_contents),\n",
    "        \"total_characters\": len(md_content),\n",
    "        \"chapters\": chapters,\n",
    "        \"job_folder\": str(job_folder),\n",
    "        \"files\": {\n",
    "            \"input_pdf\": str(original_pdf_dest),\n",
    "            \"cache\": str(cache_path),\n",
    "            \"markdown\": str(markdown_path),\n",
    "            \"metadata\": str(metadata_path)\n",
    "        }\n",
    "    }\n",
    "    with open(metadata_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(metadata_summary, f, indent=2)\n",
    "\n",
    "    print(f\"\\n✓ All files saved to: {job_folder}\")\n",
    "    print(f\"\\n  Input:\")\n",
    "    print(f\"    - {original_pdf_dest.name}\")\n",
    "    print(f\"\\n  Processed:\")\n",
    "    print(f\"    - {cache_filename} ({len(output_json) / 1024 / 1024:.2f} MB)\")\n",
    "    print(f\"    - {markdown_filename} ({len(md_content) / 1024:.1f} KB)\")\n",
    "    print(f\"    - {metadata_filename}\")\n",
    "    print(f\"\\n  Summary:\")\n",
    "    print(f\"    - {len(chapters)} chapters with metadata\")\n",
    "    print(f\"    - {len(figure_contents)} figures analyzed\")\n",
    "    print(f\"    - {len(md_content):,} characters in markdown\")\n",
    "    print(f\"\\nTotal process completed at: {datetime.now().strftime('%H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded document with 4 chapters\n"
     ]
    }
   ],
   "source": [
    "# To load a previously cached result, uncomment and specify the cache file path:\n",
    "# Example: cache_path = Path(\"../content/books/Venture-deals_textbook_20251004-143022/processed/Venture-deals_textbook_cache_20251004-143022.json\")\n",
    "# with open(cache_path, 'r', encoding='utf-8') as f:\n",
    "#     output_json = f.read()\n",
    "\n",
    "# Otherwise, use the data from the previous cell\n",
    "document_data = json.loads(output_json)\n",
    "document_content = document_data['analyzeResult']['content']\n",
    "chapters = document_data.get('chapters', [])\n",
    "document_metadata = document_data.get('document_metadata', {})\n",
    "processing_info = document_data.get('processing_info', {})\n",
    "\n",
    "print(f\"✓ Loaded document with {len(chapters)} chapters\")\n",
    "print(f\"  Document: {document_metadata.get('title', 'N/A')[:80]}...\")\n",
    "print(f\"  Content size: {len(document_content):,} characters\")\n",
    "if processing_info:\n",
    "    print(f\"  Job folder: {processing_info.get('job_folder', 'N/A')}\")\n",
    "    print(f\"  Processed: {processing_info.get('timestamp', 'N/A')}\")\n",
    "\n",
    "# Display first 20 chapters with summaries\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"CHAPTER SUMMARIES (showing first 20 of {len(chapters)})\")\n",
    "print(f\"{'='*70}\\n\")\n",
    "for i, chapter in enumerate(chapters[:20], 1):\n",
    "    chapter_num = f\"{chapter['number']}: \" if chapter['number'] else \"\"\n",
    "    print(f\"{i}. {chapter_num}{chapter['title']}\")\n",
    "    print(f\"   Pages: {chapter['page_start']}-{chapter['page_end']} | Level: {chapter['level']}\")\n",
    "    if chapter.get('summary'):\n",
    "        print(f\"   Summary: {chapter['summary'][:200]}...\" if len(chapter['summary']) > 200 else f\"   Summary: {chapter['summary']}\")\n",
    "    if chapter.get('key_topics'):\n",
    "        print(f\"   Topics: {', '.join(chapter['key_topics'][:3])}\")\n",
    "    print()\n",
    "\n",
    "# Display preview of markdown content\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"MARKDOWN CONTENT PREVIEW (first 2000 characters)\")\n",
    "print(f\"{'='*70}\\n\")\n",
    "print(document_content[:2000])\n",
    "if len(document_content) > 2000:\n",
    "    print(f\"\\n... ({len(document_content) - 2000:,} more characters)\")\n",
    "    print(f\"\\nFull content available in: {processing_info.get('job_folder', 'processed folder')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chunk text by splitting with Markdown header splitting and recursive character splitting\n",
    "This is a simple starting point. Feel free to give your own chunking strategies a try!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of chunks: 302\n",
      "Chunks with chapter metadata: 302\n",
      "\n",
      "Sample chunk metadata:\n",
      "  Chapter: \n",
      "  Topics: \n",
      "  Document: 2024 ARTICLE IV CONSULTATION-PRESS RELEASE; STAFF REPORT; AND STATEMENT BY THE EXECUTIVE DIRECTOR FOR THE UNITED STATES\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import MarkdownHeaderTextSplitter\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain.schema import Document\n",
    "\n",
    "# Configure langchain text splitting settings\n",
    "EMBEDDING_CHUNK_SIZE = 512\n",
    "EMBEDDING_CHUNK_OVERLAP = 20\n",
    "headers_to_split_on = [\n",
    "    (\"#\", \"Header 1\"),\n",
    "    (\"##\", \"Header 2\"),\n",
    "    (\"###\", \"Header 3\")\n",
    "]\n",
    "\n",
    "# First split text using Markdown headers\n",
    "text_splitter = MarkdownHeaderTextSplitter(headers_to_split_on=headers_to_split_on, strip_headers=False)\n",
    "chunks = text_splitter.split_text(document_content)\n",
    "\n",
    "# Then further split the text using recursive character text splitting\n",
    "char_text_splitter = RecursiveCharacterTextSplitter(separators=[\"<!--\", \"\\n\\n\", \"#\"], chunk_size=EMBEDDING_CHUNK_SIZE, chunk_overlap=EMBEDDING_CHUNK_OVERLAP, is_separator_regex=True)\n",
    "chunks = char_text_splitter.split_documents(chunks)\n",
    "\n",
    "# Helper function to find which chapter a chunk belongs to\n",
    "def find_chapter_for_chunk(chunk_content, chapters):\n",
    "    \"\"\"\n",
    "    Determines which chapter a chunk belongs to based on content analysis.\n",
    "    Returns chapter metadata or None.\n",
    "    \"\"\"\n",
    "    # Check if the chunk contains chapter titles or headers\n",
    "    for chapter in chapters:\n",
    "        if chapter['title'].lower() in chunk_content.lower():\n",
    "            return chapter\n",
    "    return None\n",
    "\n",
    "# Enrich chunks with chapter metadata\n",
    "enriched_chunks = []\n",
    "for chunk in chunks:\n",
    "    # Find which chapter this chunk belongs to\n",
    "    chapter = find_chapter_for_chunk(chunk.page_content, chapters)\n",
    "    \n",
    "    # Add chapter metadata to chunk\n",
    "    if chapter:\n",
    "        chunk.metadata.update({\n",
    "            \"chapter_title\": chapter['title'],\n",
    "            \"chapter_number\": chapter['number'],\n",
    "            \"chapter_level\": chapter['level'],\n",
    "            \"chapter_summary\": chapter['summary'],\n",
    "            \"chapter_topics\": \", \".join(chapter['key_topics']),\n",
    "            \"page_start\": chapter['page_start'],\n",
    "            \"page_end\": chapter['page_end']\n",
    "        })\n",
    "    \n",
    "    # Add document-level metadata\n",
    "    chunk.metadata.update({\n",
    "        \"document_title\": document_metadata.get('title', ''),\n",
    "        \"document_summary\": document_metadata.get('summary', '')\n",
    "    })\n",
    "    \n",
    "    enriched_chunks.append(chunk)\n",
    "\n",
    "print(f\"Number of chunks: {len(enriched_chunks)}\")\n",
    "print(f\"Chunks with chapter metadata: {sum(1 for c in enriched_chunks if 'chapter_title' in c.metadata)}\")\n",
    "\n",
    "# Show sample chunk with metadata\n",
    "if enriched_chunks:\n",
    "    print(f\"\\nSample chunk metadata:\")\n",
    "    if 'chapter_title' in enriched_chunks[0].metadata:\n",
    "        print(f\"  Chapter: {enriched_chunks[0].metadata.get('chapter_title')}\")\n",
    "        print(f\"  Topics: {enriched_chunks[0].metadata.get('chapter_topics')}\")\n",
    "    print(f\"  Document: {enriched_chunks[0].metadata.get('document_title', 'N/A')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query vector index to retrieve relevant documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexing 302 enriched chunks with chapter metadata...\n",
      "✓ Indexing complete\n",
      "✓ Vector store ready for chapter-aware search!\n",
      "✓ Indexing complete\n",
      "✓ Vector store ready for chapter-aware search!\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import AzureOpenAIEmbeddings\n",
    "from langchain.vectorstores.azuresearch import AzureSearch\n",
    "\n",
    "aoai_embeddings = AzureOpenAIEmbeddings(model=AZURE_OPENAI_EMBEDDING_DEPLOYMENT_NAME,\n",
    "                                        azure_endpoint=AZURE_OPENAI_ENDPOINT,\n",
    "                                        azure_ad_token_provider=token_provider,\n",
    "                                        api_version=AZURE_OPENAI_EMBEDDING_API_VERSION)\n",
    "\n",
    "vector_store = AzureSearch(\n",
    "    azure_search_endpoint=AZURE_SEARCH_ENDPOINT,\n",
    "    azure_search_key=None,\n",
    "    index_name=AZURE_SEARCH_INDEX_NAME,\n",
    "    embedding_function=aoai_embeddings.embed_query\n",
    ")\n",
    "\n",
    "# This is a one-time operation to add the documents to the vector store. Comment out this line if you are re-running this cell with the same index.\n",
    "print(f\"Indexing {len(enriched_chunks)} enriched chunks with chapter metadata...\")\n",
    "vector_store.add_documents(documents=enriched_chunks)\n",
    "print(\"✓ Indexing complete\")\n",
    "\n",
    "# Set up the retriever that will be used to query the index for similar documents\n",
    "retriever = vector_store.as_retriever(search_type=\"similarity\")\n",
    "print(\"✓ Vector store ready for chapter-aware search!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: What was the crude oil production in 2019?\n",
      "Retrieved 4 documents\n",
      "\n",
      "Document 1:\n",
      "  ID: ZDVhZGI4NTktN2Q1NS00NGQ3LThkZTEtN2VkYzA5ZTM1MGJh\n",
      "  Content: <!-- FigureContent=\"**Title**: U.S. Energy Production\n",
      "**ChartType**: line\n",
      "**TopicKeywords**: Business and finance, Energy, Environment\n",
      "**DetailedDescription**: The chart displays the production levels...\n",
      "======================================================================\n",
      "Document 2:\n",
      "  ID: ODdiODdmZmYtMjBjNC00NWQ0LTkxZDUtN2RiYjYyODQ2YmJm\n",
      "  Content: <!-- FigureContent=\"**Title**: U.S. Energy Production\n",
      "**ChartType**: line\n",
      "**TopicKeywords**: Business and finance, Energy, Environment\n",
      "**DetailedDescription**: The chart shows the production levels of...\n",
      "======================================================================\n",
      "Document 3:\n",
      "  ID: NGYxN2FiYWUtYjY0My00ZWYyLTg2MzItM2FlOTQxZDRhMDRj\n",
      "  Chapter: \n",
      "  Chapter Topics: \n",
      "  Pages: 0-0\n",
      "  Content: <!-- FigureContent=\"**Title**: U.S. Energy Production\n",
      "**ChartType**: line\n",
      "**TopicKeywords**: Business and finance, Energy, Environment\n",
      "**DetailedDescription**: The chart displays the production levels...\n",
      "======================================================================\n",
      "Document 4:\n",
      "  ID: NjRlNGNiMDgtMGU4Yy00ZGQyLTkwN2QtNTYyNDE0OTg3N2Ez\n",
      "  Content: <!-- FigureContent=\"**Title**: U.S. Energy Production\n",
      "**ChartType**: line\n",
      "**TopicKeywords**: Business and finance, Energy, Environment\n",
      "**DetailedDescription**: The chart displays the production levels...\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Retrieve relevant documents\n",
    "query = \"What was the crude oil production in 2019?\"\n",
    "retrieved_docs = retriever.invoke(query)\n",
    "\n",
    "print(f\"Query: {query}\")\n",
    "print(f\"Retrieved {len(retrieved_docs)} documents\\n\")\n",
    "\n",
    "# Print retrieved documents with chapter information\n",
    "for i, doc in enumerate(retrieved_docs, 1):\n",
    "    print(f\"Document {i}:\")\n",
    "    print(f\"  ID: {doc.metadata.get('id', 'N/A')}\")\n",
    "    if 'chapter_title' in doc.metadata:\n",
    "        print(f\"  Chapter: {doc.metadata.get('chapter_title')}\")\n",
    "        print(f\"  Chapter Topics: {doc.metadata.get('chapter_topics')}\")\n",
    "        print(f\"  Pages: {doc.metadata.get('page_start')}-{doc.metadata.get('page_end')}\")\n",
    "    print(f\"  Content: {doc.page_content[:200]}...\")\n",
    "    print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate answer to query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define system prompt template for chat model\n",
    "prompt = \"\"\"\n",
    "You are an expert in document analysis. You are proficient in reading and analyzing technical reports. You are good at numerical reasoning and have a good understanding of financial concepts. You are given a question which you need to answer based on the references provided. To answer this question, you may first read the question carefully to know what information is required or helpful to answer the question. Then, you may read the references to find the relevant information.\n",
    "\n",
    "If you find enough information to answer the question, you can first write down your thinking process and then provide a concise answer at the end.\n",
    "If you find that there is not enough information to answer the question, you can state that there is insufficient information.\n",
    "If you are not able or sure how to answer the question, say that you are not able to answer the question.\n",
    "Do not provide any information that is not present in the references.\n",
    "References are in markdown format, you may follow the markdown syntax to better understand the references.\n",
    "\n",
    "---\n",
    "References:\n",
    "{context}\n",
    "---\n",
    "\n",
    "Now, here is the question:\n",
    "---\n",
    "Question:\n",
    "{question}\n",
    "---\n",
    "Thinking Process::: \n",
    "Answer::: \n",
    "\"\"\"\n",
    "\n",
    "# Helper function to generate the formatted context from each retrieved document\n",
    "def generate_context(chunks):\n",
    "    context = []\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        s = (f'Source {i} Metadata: {chunk.metadata}\\n'\n",
    "                f'Source {i} Content: {chunk.page_content}')\n",
    "        context.append(s)\n",
    "    context = '\\n---\\n'.join(context)\n",
    "    return context\n",
    "\n",
    "# Remove redundant chunks\n",
    "appeared = set()\n",
    "unique_chunks = []\n",
    "for chunk in retrieved_docs:\n",
    "    chunk_id = chunk.metadata['id']\n",
    "    if chunk_id not in appeared:\n",
    "        appeared.add(chunk_id)\n",
    "        unique_chunks.append(chunk)\n",
    "context = generate_context(unique_chunks)\n",
    "\n",
    "# Format the prompt with the provided query and formatted context\n",
    "prompt = prompt.format(question=query,\n",
    "                       context=context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thinking process:\n",
      "- The provided chart's data table lists crude oil production by quarter.  \n",
      "- For 2019Q1 the table shows crude oil production of 12 million barrels per day.\n",
      "\n",
      "Answer:\n",
      "Crude oil production in 2019 was 12 million barrels per day.\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import AzureChatOpenAI\n",
    "\n",
    "chat_llm = AzureChatOpenAI(model=AZURE_OPENAI_CHAT_DEPLOYMENT_NAME,\n",
    "                            azure_endpoint=AZURE_OPENAI_ENDPOINT,\n",
    "                            azure_ad_token_provider=token_provider,\n",
    "                            api_version=AZURE_OPENAI_CHAT_API_VERSION,\n",
    "                            temperature=0.7)\n",
    "\n",
    "# Print the LLM's answer to the query with the retrieved documents as additional context\n",
    "answer = chat_llm.invoke(prompt)\n",
    "print(answer.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
