{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieval Augmented Generation with Content Understanding\n",
    "\n",
    "This notebook presents a guideline on how to leverage the Azure AI Content Understanding for Retrieval Augmented Generation (RAG) in document files.\n",
    "\n",
    "Leveraging Azure AI's Content Understanding Layout analysis, it extracts tables, paragraphs, and layout information from PDF files. The resulting markdown output can be utilized with LangChain's markdown header splitter, facilitating semantic chunking of documents. These chunked documents are then indexed into the Azure AI Search vector store. When a user query is received, Azure AI Search retrieves the relevant chunks, which are subsequently used to generate a context-aware response."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-requisites\n",
    "1. Follow [README](../README.md#configure-azure-ai-service-resource) to create essential resource that will be used in this sample\n",
    "2. Install required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -r ../requirements.txt\n",
    "! pip install python-dotenv langchain langchain-community langchain-openai langchainhub openai tiktoken azure-identity azure-search-documents==11.6.0b3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file in the parent directory\n",
    "env_path = Path(__file__).parent.parent / '.env' if '__file__' in globals() else Path('../.env')\n",
    "load_dotenv(dotenv_path=env_path)\n",
    "\n",
    "print(f\"✓ Loaded environment variables from: {env_path.absolute()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and validate Azure AI Services configs\n",
    "AZURE_AI_SERVICE_ENDPOINT = os.getenv(\"AZURE_AI_SERVICE_ENDPOINT\")\n",
    "AZURE_AI_SERVICE_API_VERSION = os.getenv(\"AZURE_AI_SERVICE_API_VERSION\") or \"2024-12-01-preview\"\n",
    "AZURE_DOCUMENT_INTELLIGENCE_API_VERSION = os.getenv(\"AZURE_DOCUMENT_INTELLIGENCE_API_VERSION\") or \"2024-11-30\"\n",
    "\n",
    "# Load and validate Azure OpenAI configs\n",
    "AZURE_OPENAI_ENDPOINT = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "AZURE_OPENAI_CHAT_DEPLOYMENT_NAME = os.getenv(\"AZURE_OPENAI_CHAT_DEPLOYMENT_NAME\")\n",
    "AZURE_OPENAI_CHAT_API_VERSION = os.getenv(\"AZURE_OPENAI_CHAT_API_VERSION\") or \"2024-08-01-preview\"\n",
    "AZURE_OPENAI_EMBEDDING_DEPLOYMENT_NAME = os.getenv(\"AZURE_OPENAI_EMBEDDING_DEPLOYMENT_NAME\")\n",
    "AZURE_OPENAI_EMBEDDING_API_VERSION = os.getenv(\"AZURE_OPENAI_EMBEDDING_API_VERSION\") or \"2023-05-15\"\n",
    "\n",
    "# Load and validate Azure Search Services configs\n",
    "AZURE_SEARCH_ENDPOINT = os.getenv(\"AZURE_SEARCH_ENDPOINT\")\n",
    "AZURE_SEARCH_INDEX_NAME = os.getenv(\"AZURE_SEARCH_INDEX_NAME\") or \"sample-doc-index\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create custom analyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Markdown <!-- PageHeader=\"This is the header of the document.\" -->\n",
      "\n",
      "\n",
      "# This is title\n",
      "\n",
      "\n",
      "## 1. Text\n",
      "\n",
      "Latin refers to an ancient Italic language\n",
      "originating in the region of Latium in\n",
      "ancient Rome.\n",
      "\n",
      "\n",
      "## 2. Page Objects\n",
      "\n",
      "\n",
      "### 2.1 Table\n",
      "\n",
      "Here's a sample table below, designed to\n",
      "be simple for easy understand and quick\n",
      "reference.\n",
      "\n",
      "\n",
      "<table>\n",
      "<caption>Table 1: This is a dummy table</caption>\n",
      "<tr>\n",
      "<th>Name</th>\n",
      "<th>Corp</th>\n",
      "<th>Remark</th>\n",
      "</tr>\n",
      "<tr>\n",
      "<td>Foo</td>\n",
      "<td></td>\n",
      "<td></td>\n",
      "</tr>\n",
      "<tr>\n",
      "<td>Bar</td>\n",
      "<td>Microsoft</td>\n",
      "<td>Dummy</td>\n",
      "</tr>\n",
      "</table>\n",
      "\n",
      "\n",
      "### 2.2. Figure\n",
      "\n",
      "\n",
      "<figure>\n",
      "<figcaption>Figure 1: Here is a figure with text</figcaption>\n",
      "\n",
      "Values\n",
      "\n",
      "500\n",
      "\n",
      "450\n",
      "\n",
      "400\n",
      "\n",
      "400\n",
      "\n",
      "350\n",
      "\n",
      "300\n",
      "\n",
      "300\n",
      "\n",
      "250\n",
      "\n",
      "200\n",
      "\n",
      "200\n",
      "\n",
      "100\n",
      "\n",
      "0\n",
      "\n",
      "Jan\n",
      "\n",
      "Feb\n",
      "\n",
      "Mar\n",
      "\n",
      "Apr\n",
      "\n",
      "May\n",
      "\n",
      "Jun\n",
      "\n",
      "Months\n",
      "\n",
      "</figure>\n",
      "\n",
      "\n",
      "## 3. Others\n",
      "\n",
      "Al Document Intelligence is an Al service\n",
      "that applies advanced machine learning\n",
      "to extract text, key-value pairs, tables,\n",
      "and structures from documents\n",
      "automatically and accurately:\n",
      "\n",
      "☒\n",
      "clear\n",
      "\n",
      "☒\n",
      "precise\n",
      "\n",
      "☐\n",
      "vague\n",
      "\n",
      "☒\n",
      "coherent\n",
      "\n",
      "☐\n",
      "Incomprehensible\n",
      "\n",
      "Turn documents into usable data and\n",
      "shift your focus to acting on information\n",
      "rather than compiling it. Start with\n",
      "prebuilt models or create custom models\n",
      "tailored to your documents both on\n",
      "premises and in the cloud with the Al\n",
      "Document Intelligence studio or SDK.\n",
      "\n",
      "Learn how to accelerate your business\n",
      "processes by automating text extraction\n",
      "with Al Document Intelligence. This\n",
      "webinar features hands-on demos for key\n",
      "use cases such as document processing,\n",
      "knowledge mining, and industry-specific\n",
      "Al model customization.\n",
      "\n",
      "<!-- PageFooter=\"This is the footer of the document.\" -->\n",
      "<!-- PageNumber=\"1 | Page\" -->\n",
      "\n",
      "{\n",
      "  \"id\": \"63f22537-82c1-4abb-b904-751741244be1\",\n",
      "  \"status\": \"Succeeded\",\n",
      "  \"result\": {\n",
      "    \"analyzerId\": \"layout-sample-924ab119-2ff9-4fa4-8e45-d23aff225689\",\n",
      "    \"apiVersion\": \"2024-12-01-preview\",\n",
      "    \"createdAt\": \"2025-10-04T00:36:56Z\",\n",
      "    \"warnings\": [],\n",
      "    \"contents\": [\n",
      "      {\n",
      "        \"markdown\": \"<!-- PageHeader=\\\"This is the header of the document.\\\" -->\\n\\n\\n# This is title\\n\\n\\n## 1. Text\\n\\nLatin refers to an ancient Italic language\\noriginating in the region of Latium in\\nancient Rome.\\n\\n\\n## 2. Page Objects\\n\\n\\n### 2.1 Table\\n\\nHere's a sample table below, designed to\\nbe simple for easy understand and quick\\nreference.\\n\\n\\n<table>\\n<caption>Table 1: This is a dummy table</caption>\\n<tr>\\n<th>Name</th>\\n<th>Corp</th>\\n<th>Remark</th>\\n</tr>\\n<tr>\\n<td>Foo</td>\\n<td></td>\\n<td></td>\\n</tr>\\n<tr>\\n<td>Bar</td>\\n<td>Microsoft</td>\\n<td>Dummy</td>\\n</tr>\\n</table>\\n\\n\\n### 2.2. Figure\\n\\n\\n<figure>\\n<figcaption>Figure 1: Here is a figure with text</figcaption>\\n\\nValues\\n\\n500\\n\\n450\\n\\n400\\n\\n400\\n\\n350\\n\\n300\\n\\n300\\n\\n250\\n\\n200\\n\\n200\\n\\n100\\n\\n0\\n\\nJan\\n\\nFeb\\n\\nMar\\n\\nApr\\n\\nMay\\n\\nJun\\n\\nMonths\\n\\n</figure>\\n\\n\\n## 3. Others\\n\\nAl Document Intelligence is an Al service\\nthat applies advanced machine learning\\nto extract text, key-value pairs, tables,\\nand structures from documents\\nautomatically and accurately:\\n\\n\\u2612\\nclear\\n\\n\\u2612\\nprecise\\n\\n\\u2610\\nvague\\n\\n\\u2612\\ncoherent\\n\\n\\u2610\\nIncomprehensible\\n\\nTurn documents into usable data and\\nshift your focus to acting on information\\nrather than compiling it. Start with\\nprebuilt models or create custom models\\ntailored to your documents both on\\npremises and in the cloud with the Al\\nDocument Intelligence studio or SDK.\\n\\nLearn how to accelerate your business\\nprocesses by automating text extraction\\nwith Al Document Intelligence. This\\nwebinar features hands-on demos for key\\nuse cases such as document processing,\\nknowledge mining, and industry-specific\\nAl model customization.\\n\\n<!-- PageFooter=\\\"This is the footer of the document.\\\" -->\\n<!-- PageNumber=\\\"1 | Page\\\" -->\\n\",\n",
      "        \"kind\": \"document\",\n",
      "        \"startPageNumber\": 1,\n",
      "        \"endPageNumber\": 1,\n",
      "        \"unit\": \"inch\",\n",
      "        \"pages\": [\n",
      "          {\n",
      "            \"pageNumber\": 1,\n",
      "            \"angle\": 0.07332411,\n",
      "            \"width\": 5.1667,\n",
      "            \"height\": 6.7083\n",
      "          }\n",
      "        ]\n",
      "      }\n",
      "    ]\n",
      "  }\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Response [204]>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import logging\n",
    "import os\n",
    "import json\n",
    "import sys\n",
    "import uuid\n",
    "from pathlib import Path\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "from azure.identity import DefaultAzureCredential, get_bearer_token_provider\n",
    "\n",
    "#File location\n",
    "DOC_LOCATION = Path(\"../data/sample_layout.pdf\")\n",
    "\n",
    "# Add the parent directory to the path to use shared modules\n",
    "parent_dir = Path(Path.cwd()).parent\n",
    "sys.path.append(str(parent_dir))\n",
    "\n",
    "from python.content_understanding_client import AzureContentUnderstandingClient\n",
    "credential = DefaultAzureCredential()\n",
    "token_provider = get_bearer_token_provider(credential, \"https://cognitiveservices.azure.com/.default\")\n",
    "\n",
    "\n",
    "ANALYZER_TEMPLATE_PATH = \"../analyzer_templates/content_document.json\"\n",
    "ANALYZER_ID = \"layout-sample-\" + str(uuid.uuid4())\n",
    "\n",
    "# Create Content Understanding client\n",
    "content_understanding_client = AzureContentUnderstandingClient(\n",
    "    endpoint=AZURE_AI_SERVICE_ENDPOINT,\n",
    "    api_version=AZURE_AI_SERVICE_API_VERSION,\n",
    "    token_provider=token_provider,\n",
    "    x_ms_useragent=\"azure-ai-content-understanding-python/content_extraction\", # This header is used for sample usage telemetry, please comment out this line if you want to opt out.\n",
    ")\n",
    "\n",
    "# Create analyzer and use analyzer to extract document content with layout analysis\n",
    "try:\n",
    "    # Create analyzer\n",
    "    response = content_understanding_client.begin_create_analyzer(ANALYZER_ID, analyzer_template_path=ANALYZER_TEMPLATE_PATH)\n",
    "    result = content_understanding_client.poll_result(response)\n",
    "    \n",
    "    # Analyze document\n",
    "    response = content_understanding_client.begin_analyze(ANALYZER_ID, file_location=DOC_LOCATION)\n",
    "    result = content_understanding_client.poll_result(response)\n",
    "    result_data = result.get(\"result\", {})\n",
    "    contents = result_data.get(\"contents\", [])\n",
    "\n",
    "    #extract markdown content\n",
    "    for content in contents:\n",
    "        markdown_content = content.get(\"markdown\", \"\")\n",
    "        print(f\"Markdown\", markdown_content)\n",
    "    print(json.dumps(result, indent=2))\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    print(\"Error in creating analyzer. Please double-check your analysis settings.\\nIf there is a conflict, you can delete the analyzer and then recreate it, or move to the next cell and use the existing analyzer.\")\n",
    "\n",
    "# Delete the analyzer if it is no longer needed\n",
    "content_understanding_client.delete_analyzer(ANALYZER_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split document content into semantic chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of splits: 5\n"
     ]
    }
   ],
   "source": [
    "from langchain import hub\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain_openai import AzureOpenAIEmbeddings\n",
    "from langchain.schema import StrOutputParser\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "from langchain.text_splitter import MarkdownHeaderTextSplitter\n",
    "from langchain.vectorstores.azuresearch import AzureSearch\n",
    "# Configure langchain text splitting settings\n",
    "EMBEDDING_CHUNK_SIZE = 512\n",
    "EMBEDDING_CHUNK_OVERLAP = 20\n",
    "\n",
    "# Split the document into chunks base on markdown headers.\n",
    "headers_to_split_on = [\n",
    "    (\"#\", \"Header 1\"),\n",
    "    (\"##\", \"Header 2\"),\n",
    "    (\"###\", \"Header 3\"),\n",
    "]\n",
    "\n",
    "text_splitter = MarkdownHeaderTextSplitter(headers_to_split_on=headers_to_split_on)\n",
    "\n",
    "docs_string = markdown_content\n",
    "splits = text_splitter.split_text(docs_string)\n",
    "\n",
    "print(\"Length of splits: \" + str(len(splits)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embed and index the chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embed the splitted documents and insert into Azure Search vector store\n",
    "def embed_and_index_chunks(docs):\n",
    "    aoai_embeddings = AzureOpenAIEmbeddings(\n",
    "        azure_deployment=AZURE_OPENAI_EMBEDDING_DEPLOYMENT_NAME,\n",
    "        openai_api_version=AZURE_OPENAI_EMBEDDING_API_VERSION,  # e.g., \"2023-12-01-preview\"\n",
    "        azure_endpoint=AZURE_OPENAI_ENDPOINT,\n",
    "        azure_ad_token_provider=token_provider\n",
    "    )\n",
    "\n",
    "    vector_store: AzureSearch = AzureSearch(\n",
    "        azure_search_endpoint=AZURE_SEARCH_ENDPOINT,\n",
    "        azure_search_key=None,\n",
    "        index_name=AZURE_SEARCH_INDEX_NAME,\n",
    "        embedding_function=aoai_embeddings.embed_query\n",
    "    )\n",
    "    vector_store.add_documents(documents=docs)\n",
    "    return vector_store\n",
    "\n",
    "\n",
    "# embed and index the docs:\n",
    "vector_store = embed_and_index_chunks(splits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieve relevant chunks based on a question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###\n"
     ]
    }
   ],
   "source": [
    "# Retrieve relevant chunks based on the question\n",
    "\n",
    "retriever = vector_store.as_retriever(search_type=\"similarity\", k=3)\n",
    "\n",
    "retrieved_docs = retriever.invoke(\n",
    "    \"<your question>\"\n",
    ")\n",
    "\n",
    "print(retrieved_docs[0].page_content)\n",
    "\n",
    "# Use a prompt for RAG that is checked into the LangChain prompt hub (https://smith.langchain.com/hub/rlm/rag-prompt?organizationId=989ad331-949f-4bac-9694-660074a208a7)\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "llm = AzureChatOpenAI(\n",
    "    openai_api_version=AZURE_OPENAI_CHAT_API_VERSION,  # e.g., \"2023-12-01-preview\"\n",
    "    azure_deployment=AZURE_OPENAI_CHAT_DEPLOYMENT_NAME,\n",
    "    temperature=1,\n",
    "    azure_ad_token_provider=token_provider\n",
    ")\n",
    "\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document Q & A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The document\\'s main theme is a page header—it\\'s a repeated header placeholder (\"This is the header of the document.\").'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ask a question about the document\n",
    "\n",
    "rag_chain.invoke(\"What is the main theme of the document?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document Q&A with references"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return the retrieved documents or certain source metadata from the documents\n",
    "\n",
    "from operator import itemgetter\n",
    "\n",
    "from langchain.schema.runnable import RunnableMap\n",
    "\n",
    "rag_chain_from_docs = (\n",
    "    {\n",
    "        \"context\": lambda input: format_docs(input[\"documents\"]),\n",
    "        \"question\": itemgetter(\"question\"),\n",
    "    }\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "rag_chain_with_source = RunnableMap(\n",
    "    {\"documents\": retriever, \"question\": RunnablePassthrough()}\n",
    ") | {\n",
    "    \"documents\": lambda input: [doc.metadata for doc in input[\"documents\"]],\n",
    "    \"answer\": rag_chain_from_docs,\n",
    "}\n",
    "\n",
    "rag_chain_with_source.invoke(\"What is the longest word in the document?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
